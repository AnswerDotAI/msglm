{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Create messages for language models like Claude and OpenAI GPTs (including Azure OpenAI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import base64\n",
    "import mimetypes\n",
    "from collections.abc import Mapping\n",
    "\n",
    "from fastcore import imghdr\n",
    "from fastcore.meta import delegates\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anthropic's Claude and OpenAI's GPT models are some of the most popular LLMs. \n",
    "\n",
    "Let's take a look at their APIs and to learn how we should structure our messages for a simple text chat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0e31fb3c9c3089d500693937a77a6c8194889e95247c1f316d', created_at=1765357479.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_0e31fb3c9c3089d500693937a8122c81948f695ad3f5cdc081', content=[ResponseOutputText(annotations=[], text='Hello, world! ðŸŒ  \\nHow can I help you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=11, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=15, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=26), user=None, billing={'payer': 'developer'}, store=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "client.responses.create(\n",
    "  model=\"gpt-4.1\",\n",
    "  input=[ {\"role\": \"user\", \"content\": \"Hello, world!\"} ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### azure/openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-ClAR7iIxGFYHPyjERTnZ4R8FIzHmD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! ðŸŒ How can I help you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1765357569, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier=None, system_fingerprint='fp_f99638a8d7', usage=CompletionUsage(completion_tokens=12, prompt_tokens=11, total_tokens=23, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az_res = client.chat.completions.create(\n",
    "    model=\"Gpt4.1\",\n",
    "    messages=[ {\"role\": \"user\", \"content\": \"Hello, world!\"} ]\n",
    ")\n",
    "az_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_018eV3E7midA69EEb6EvGuPr', content=[TextBlock(citations=None, text=\"Hello! It's nice to meet you. As an AI assistant, I'm here to help with any questions or tasks you may have. Please feel free to ask me anything, and I'll do my best to assist you.\", type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation=CacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=11, output_tokens=49, server_tool_use=None, service_tier='standard'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Anthropic()\n",
    "\n",
    "client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1024,\n",
    "    messages=[ {\"role\": \"user\", \"content\": \"Hello, world!\"} ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the APIs use the exact same message structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mk_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's build the first version of `mk_msg` to handle this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_msg(content:str, role:str=\"user\")->dict:\n",
    "    \"Create an OpenAI/Anthropic compatible message.\"\n",
    "    return dict(role=role, content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out with the OpenAI API. To do that we'll need to setup two things:\n",
    "\n",
    "- install the openai SDK by running `pip install openai`\n",
    "- add your openai api key to your env vars `export OPENAI_API_KEY=\"YOUR_OPEN_API_KEY\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oa_cli = OpenAI()\n",
    "\n",
    "r = oa_cli.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[mk_msg(\"Hello, world!\")]\n",
    ")\n",
    "r.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Azure/OpenAI API, the Python openai module provides the required class, but we must set the following environment variables:\n",
    "\n",
    "- `export AZURE_OPENAI_API_KEY=\"YOUR_API_KEY\"`\n",
    "- `export OPENAI_API_VERSION=\"API_VERSION\"`\n",
    "- `export AZURE_OPENAI_ENDPOINT=\"ENDPOINT_URL\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! ðŸŒ How can I help you today?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az_cli = AzureOpenAI()\n",
    "\n",
    "r = az_cli.chat.completions.create(\n",
    "    model=\"Gpt4.1\",\n",
    "    messages=[mk_msg(\"Hello, world!\")]\n",
    ")\n",
    "\n",
    "r.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test out `mk_msg` on the Anthropic API. To do that we'll need to setup two things:\n",
    "\n",
    "- install the openai SDK by running `pip install anthropic`\n",
    "- add your anthropic api key to your env vars `export ANTHROPIC_API_KEY=\"YOUR_ANTHROPIC_API_KEY\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm an AI assistant created by Anthropic. How can I assist you today?\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_cli = Anthropic()\n",
    "\n",
    "r = a_cli.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1024,\n",
    "    messages=[mk_msg(\"Hello, world!\")]\n",
    ")\n",
    "r.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going any further, let's create some helper functions to make it a little easier to call the OpenAI and Anthropic APIs. We're going to be making a bunch of API calls to test our code and typing the full expressions out each time will become a little tedious. These functions won't be included in the final package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_chat(msgs: list)->tuple:\n",
    "    \"call the openai chat responses endpoint with `msgs`.\"\n",
    "    r = oa_cli.responses.create(model=\"o4-mini\", input=msgs)\n",
    "    return r, r.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check that `mk_msg` still works with our simple text example from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I assist you today?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, text = openai_chat([mk_msg(\"Hello, world!\")])\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Azure/OpenAI..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_chat(msgs:list)->tuple:\n",
    "    \"call the azure/openai messages endpoint with `msgs`.\"\n",
    "    r = az_cli.chat.completions.create(model=\"Gpt4.1\", messages=msgs)\n",
    "    return r, r.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! ðŸŒ How can I assist you today?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, text = azure_chat([mk_msg(\"Hello, world!\")])\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Anthropic..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_cli = Anthropic()\n",
    "\n",
    "def anthropic_chat(msgs: list)->tuple:\n",
    "    \"call the anthropic messages endpoint with `msgs`.\"\n",
    "    r = a_cli.messages.create(model=\"claude-sonnet-4-20250514\", max_tokens=1024, messages=msgs)\n",
    "    return r, r.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! Nice to meet you! How are you doing today? Is there anything I can help you with?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, text = anthropic_chat([mk_msg(\"Hello, world!\")])\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's see how the APIs handle image messages.\n",
    "\n",
    "<img src=\"https://claudette.answer.ai/index_files/figure-html/cell-35-output-1.jpeg\" height=240 width=240></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://claudette.answer.ai/index_files/figure-html/cell-35-output-1.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtype = \"image/jpeg\"\n",
    "img_content = httpx.get(img_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image features a cute puppy lying on the grass near some purple flowers. The puppy has a white coat with brown patches and appears inquisitive and playful.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = base64.b64encode(img_content).decode(\"utf-8\")\n",
    "\n",
    "client = OpenAI()\n",
    "r = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\": [\n",
    "                {\"type\":\"input_text\",\"text\":\"What's in this image?\"},\n",
    "                {\"type\":\"input_image\",\"image_url\":f\"data:image/jpeg;base64,{img}\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "r.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### azure/openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image shows a small dog with white fur and brown ears lying on the grass next to a bunch of purple flowers. There is also a wooden object in the background.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtype = \"image/jpeg\"\n",
    "img = base64.b64encode(img_content).decode(\"utf-8\")\n",
    "\n",
    "r = az_cli.chat.completions.create(\n",
    "    model=\"Gpt4.1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\": [\n",
    "                {\"type\":\"text\",\"text\":\"What's in this image?\"},\n",
    "                {\"type\":\"image_url\",\"image_url\": {'url': f\"data:image/jpeg;base64,{img}\"}},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "r.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This image shows a cute puppy lying on the grass. The puppy appears to be a Cavalier King Charles Spaniel, with a long, silky coat that is brown and white in color. The puppy has a sweet, friendly expression as it gazes out at the viewer. In the background, there are some purple flowers, likely daisies or asters, adding a nice natural element to the scene.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtype = \"image/jpeg\"\n",
    "img = base64.b64encode(img_content).decode(\"utf-8\")\n",
    "\n",
    "client = Anthropic()\n",
    "r = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\": [\n",
    "                {\"type\":\"text\",\"text\":\"What's in this image?\"},\n",
    "                {\"type\":\"image\",\"source\":{\"type\":\"base64\",\"media_type\":mtype,\"data\":img}}\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "r.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALl three APIs format images slightly differently and the structure of the message `content` is a little more complex. \n",
    "\n",
    "In a text chat, `content` is a simple string but for a multimodal chat (text+images) we can see that `content` is a list of dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Msg Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create `_mk_img` to make our code a little DRY'r. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _mk_img(data:bytes)->tuple:\n",
    "    \"Convert image bytes to a base64 encoded image\"\n",
    "    img = base64.b64encode(data).decode(\"utf-8\")\n",
    "    mtype = mimetypes.types_map[\".\"+imghdr.what(None, h=data)]\n",
    "    return img, mtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the additional complexity of multimodal messages let's build a `Msg` class for the `content` data structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": \"What's in this image?\"}],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Msg:\n",
    "    \"Helper class to create a message for the OpenAI and Anthropic APIs.\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all three APIs handle images differently let's subclass `Msg` for each API and handle the image formatting in a method called `img_msg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class OpenAiMsg(Msg):\n",
    "    \"Helper class to create a message for the OpenAI API.\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AzureMsg(Msg):\n",
    "    \"Helper class to create a message for the Azure OpenAI API.\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class AnthropicMsg(Msg):\n",
    "    \"Helper class to create a message for the Anthropic API.\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some helper functions for `mk_content` to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _is_img(data): return isinstance(data, bytes) and bool(imghdr.what(None, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PDF [file](https://docs.fileformat.com/pdf/#pdf-file-header) should start with `%PDF` followed by the pdf version `%PDF-1.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _is_pdf(data): \n",
    "    is_byte_pdf = isinstance(data, bytes) and data.startswith(b'%PDF-')\n",
    "    is_pdf_url = isinstance(data, str) and (\n",
    "        data.startswith(\"http\") and (data.endswith(\".pdf\") or 'pdf' in data.split('/'))\n",
    "    )\n",
    "    return is_byte_pdf or is_pdf_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _is_pdf(\"https://arxiv.org/pdf/2301.00001\")\n",
    "assert not _is_pdf(\"https://arxiv.org/abs/2301.00001\")\n",
    "assert _is_pdf(\"https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf\")\n",
    "assert not _is_pdf(\"Hi /pdf/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an appropriate type based on content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def mk_content(self:Msg, content, text_only=False)->dict:\n",
    "    if _is_img(content): return self.img_msg(content)\n",
    "    if _is_pdf(content): return self.pdf_msg(content)\n",
    "    if isinstance(content, str): return self.text_msg(content, text_only=text_only)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¦then we call the model with this content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def __call__(self:Msg, role:str, content:[list, str], text_only:bool=False, **kw)->dict:\n",
    "    \"Create an OpenAI/Anthropic compatible message with `role` and `content`.\"\n",
    "    if content is not None and not isinstance(content, list): content = [content]\n",
    "    content = [self.mk_content(o, text_only=text_only) for o in content] if content else ''\n",
    "    return dict(role=role, content=content[0] if text_only else content, **kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def img_msg(self:OpenAiMsg, data:bytes)->dict:\n",
    "    \"Convert `data` to an image message\"\n",
    "    img, mtype = _mk_img(data)\n",
    "    return {\"type\": \"input_image\", \"image_url\": f\"data:{mtype};base64,{img}\"}\n",
    "\n",
    "@patch\n",
    "def text_msg(self:OpenAiMsg, s:str, text_only=False)->dict: \n",
    "    \"Convert `s` to a text message\"\n",
    "    if not s.strip(): s='.'\n",
    "    return s if text_only else {\"type\": \"input_text\", \"text\":s}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure/OpenAI implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def img_msg(self:AzureMsg, data:bytes)->dict:\n",
    "    \"Convert `data` to an image message\"\n",
    "    img, mtype = _mk_img(data)\n",
    "    return {\"type\": \"image_url\", \"image_url\": {'url': f\"data:{mtype};base64,{img}\"}}\n",
    "\n",
    "@patch\n",
    "def text_msg(self:AzureMsg, s:str, text_only=False)->dict: \n",
    "    \"Convert `s` to a text message\"\n",
    "    if not s.strip(): s='.'\n",
    "    return s if text_only else {\"type\": \"text\", \"text\":s}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anthropic implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def img_msg(self:AnthropicMsg, data:bytes)->dict:\n",
    "    \"Convert `data` to an image message\"\n",
    "    img, mtype = _mk_img(data)\n",
    "    r = {\"type\": \"base64\", \"media_type\": mtype, \"data\":img}\n",
    "    return {\"type\": \"image\", \"source\": r}\n",
    "\n",
    "@patch\n",
    "def text_msg(self:AnthropicMsg, s:str, text_only=False)->dict: \n",
    "    \"Convert `s` to a text message\"\n",
    "    if not s.strip(): s='.'\n",
    "    return s if text_only else {\"type\": \"text\", \"text\":s}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update `mk_msg` to use `Msg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "PROVIDER_MSG = {\n",
    "    'openai': OpenAiMsg,\n",
    "    'azure': AzureMsg,\n",
    "    'anthropic': AnthropicMsg,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_msg(content:Union[list,str], role:str=\"user\", *args, api:str=\"openai\", **kw)->dict:\n",
    "    \"Create an OpenAI/Anthropic compatible message.\"\n",
    "    text_only = isinstance(content, str) or (isinstance(content, list) and len(content) == 1 and isinstance(content[0], str))\n",
    "    m = PROVIDER_MSG[api]\n",
    "    msg = m()(role, content, text_only=text_only, **kw)\n",
    "    return dict2obj(msg, list_func=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "{ 'content': [ {'text': 'Hello world', 'type': 'input_text'},\n",
       "               {'text': 'how are you?', 'type': 'input_text'}],\n",
       "  'role': 'user'}\n",
       "```"
      ],
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': [{'type': 'input_text', 'text': 'Hello world'},\n",
       "  {'type': 'input_text', 'text': 'how are you?'}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_msg([\"Hello world\", \"how are you?\"], api='openai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "{ 'content': [ {'text': 'Hello world', 'type': 'text'},\n",
       "               {'text': 'how are you?', 'type': 'text'}],\n",
       "  'role': 'user'}\n",
       "```"
      ],
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': [{'type': 'text', 'text': 'Hello world'},\n",
       "  {'type': 'text', 'text': 'how are you?'}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_msg([\"Hello world\", \"how are you?\"], api='azure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "{ 'content': [ {'text': 'Hello world', 'type': 'text'},\n",
       "               {'text': 'how are you?', 'type': 'text'}],\n",
       "  'role': 'user'}\n",
       "```"
      ],
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': [{'type': 'text', 'text': 'Hello world'},\n",
       "  {'type': 'text', 'text': 'how are you?'}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_msg([\"Hello world\", \"how are you?\"], api='anthropic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image shows a small puppyâ€”likely a Cavalier King Charles Spanielâ€”resting on a patch of green grass. Its fur is predominantly white, with rich chestnut-brown patches on its floppy ears and around its eyes. The puppyâ€™s dark, round eyes gaze directly at the camera, giving it an inquisitive, gentle expression. Behind it, thereâ€™s a cluster of small purple daisy-like flowers and a wooden surface (perhaps a low bench or planter). Soft, natural light illuminates the scene, highlighting the puppyâ€™s silky coat and the vibrant colors of the grass and blossoms.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = mk_msg([img_content, \"describe this picture\"], api=\"openai\")\n",
    "_, text = openai_chat([msg])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A dog with a white body and brown ears is lying on the grass near a bunch of purple flowers. The background includes greenery and a rustic-looking surface. The scene appears peaceful and outdoorsy, with the dog relaxing in a garden setting.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = mk_msg([img_content, \"describe this picture\"], api=\"azure\")\n",
    "_, text = azure_chat([msg])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This adorable image shows a young puppy, likely a Cavalier King Charles Spaniel, sitting in a garden setting. The puppy has beautiful reddish-brown and white fur with distinctive markings - a white blaze down the center of its face and white chest, contrasted with rich brown coloring around the ears and eyes. The puppy has sweet, dark eyes and appears to be quite young.\\n\\nThe setting is charming, with the puppy positioned near some purple flowers (possibly asters or similar small blooms) and sitting on what appears to be green grass or moss. There's a rustic brick or stone wall visible in the background, creating a lovely garden atmosphere. The lighting appears soft and natural, giving the whole scene a warm, peaceful quality that perfectly complements the puppy's gentle expression.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = mk_msg([img_content, \"describe this picture\"], api=\"anthropic\")\n",
    "_, text = anthropic_chat([msg])\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about chatting with PDFs? Unfortunately, OpenAI's message completions API doesn't offer PDF support at the moment, but Claude [does](https://docs.anthropic.com/en/docs/build-with-claude/pdf-support). \n",
    "\n",
    "Under the hood, Claude extracts the text from the PDF and converts each page to an image. This means you can ask Claude about any text, pictures, charts, and tables in the PDF. Here's an example from the Claude [docs](https://docs.anthropic.com/en/docs/build-with-claude/pdf-support#how-to-use-pdfs-in-the-messages-api). Overall the message structure is pretty similar to an image message.\n",
    "\n",
    "```python\n",
    "pdf_url = \"https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf\"\n",
    "pdf_data = base64.standard_b64encode(httpx.get(pdf_url).content).decode(\"utf-8\")\n",
    "client = anthropic.Anthropic()\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\", max_tokens=1024,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"document\",\n",
    "                \"source\": { \"type\": \"base64\", \"media_type\": \"application/pdf\", \"data\": pdf_data }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Which model has the highest human preference win rates across each use-case?\"\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Anthropic API has since offered an option for PDFs that can be accessed online via url.\n",
    "\n",
    "```python\n",
    "client = anthropic.Anthropic()\n",
    "message = client.messages.create(\n",
    "    model=\"claude-opus-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"url\",\n",
    "                        \"url\": \"https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What are the key findings in this document?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a method that converts a byte string to the base64 encoded string that Anthropic expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _mk_pdf(data:bytes)->str:\n",
    "    \"Convert pdf bytes to a base64 encoded pdf\"\n",
    "    return base64.standard_b64encode(data).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a `pdf_msg` method to `AnthropicMsg` that uses `_mk_pdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def pdf_msg(self:AnthropicMsg, data: bytes | str) -> dict:\n",
    "    \"Convert `data` to a pdf message\"\n",
    "    if isinstance(data, bytes):\n",
    "        r = {\"type\": \"base64\", \"media_type\": \"application/pdf\", \"data\":_mk_pdf(data)}\n",
    "    elif isinstance(data, str):\n",
    "        r = {\"type\": \"url\", \"url\": data}\n",
    "    return {\"type\": \"document\", \"source\": r}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our changes on a financial report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = Path('financial_report.pdf').read_bytes()\n",
    "msg = mk_msg([pdf, \"what was the average monthly revenue for product D?\"], api=\"anthropic\")\n",
    "_, text = anthropic_chat([msg])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_url = \"https://arxiv.org/pdf/2506.18880\"\n",
    "msg = mk_msg([pdf_url, \"What were the three types of generalization the authors of this paper looked at?\"], api=\"anthropic\")\n",
    "_, text = anthropic_chat([msg])\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs are stateless. To continue a conversation we need to include the entire message history in every API call.\n",
    "By default the role in each message alternates between `user` and `assistant`.\n",
    "\n",
    "Let's add a method that alternates the roles for us and then calls `mk_msgs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_msgs(msgs: list, *args, api:str=\"openai\", **kw) -> list:\n",
    "    \"Create a list of messages compatible with OpenAI/Anthropic.\"\n",
    "    if isinstance(msgs, str): msgs = [msgs]\n",
    "    return [mk_msg(o, ('user', 'assistant')[i % 2], *args, api=api, **kw) for i, o in enumerate(msgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hello'},\n",
       " {'role': 'assistant', 'content': 'Some assistant response'},\n",
       " {'role': 'user', 'content': 'tell me a joke'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_msgs([\"Hello\", \"Some assistant response\", \"tell me a joke\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDK Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our lives even easier, it would be nice if `mk_msg` could format the SDK objects returned from a previous chat so that we can pass them straight to `mk_msgs`.\n",
    "\n",
    "The OpenAI SDK accepts objects like `ChatCompletion` as messages. Anthropic is different and expects every message to have the `role`, `content` format that we've seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __call__(self:Msg, role:str, content:[list,str], text_only:bool=False, **kw)->dict:\n",
    "    \"Create an OpenAI/Anthropic compatible message with `role` and `content`.\"\n",
    "    if self.sdk_obj_support and self.is_sdk_obj(content): return self.find_block(content)\n",
    "    if hasattr(content, \"content\"): content, role = content.content, content.role\n",
    "    content = self.find_block(content)\n",
    "    if content is not None and not isinstance(content, list): content = [content]\n",
    "    content = [self.mk_content(o, text_only=text_only) for o in content] if content else ''\n",
    "    return dict(role=role, content=content[0] if text_only else content, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "AnthropicMsg.sdk_obj_support=False\n",
    "OpenAiMsg.sdk_obj_support=True\n",
    "AzureMsg.sdk_obj_support=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def is_sdk_obj(self:AnthropicMsg, r)-> bool:\n",
    "    \"Check if `r` is an SDK object.\"\n",
    "    return isinstance(r, Mapping)\n",
    "\n",
    "@patch\n",
    "def find_block(self:AnthropicMsg, r):\n",
    "    \"Find the message in `r`.\"\n",
    "    return r.get('content', r) if self.is_sdk_obj(r) else r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def is_sdk_obj(self:OpenAiMsg, r)-> bool:\n",
    "    \"Check if `r` is an SDK object.\"\n",
    "    return not isinstance(r, (str,bytes,list))\n",
    "\n",
    "@patch\n",
    "def find_block(self:OpenAiMsg, r):\n",
    "    \"Find the message in `r`.\"\n",
    "    if isinstance(r,Mapping): return r\n",
    "    if hasattr(r, \"output\"): return r.output\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def is_sdk_obj(self:AzureMsg, r)-> bool:\n",
    "    \"Check if `r` is an SDK object.\"\n",
    "    return not isinstance(r, (str,bytes,list))\n",
    "\n",
    "@patch\n",
    "def find_block(self:AzureMsg, r):\n",
    "    \"Find the message in `r`.\"\n",
    "    return getattr(r.choices[0].message, 'content', r) if self.is_sdk_obj(r) else r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_msgs(msgs: list, *args, api:str=\"openai\", **kw) -> list:\n",
    "    \"Create a list of messages compatible with OpenAI/Anthropic.\"\n",
    "    if isinstance(msgs, str): msgs = [msgs]\n",
    "    mm = [mk_msg(o, ('user', 'assistant')[i % 2], *args, api=api, **kw) for i, o in enumerate(msgs)]\n",
    "    res = []\n",
    "    for o in mm:\n",
    "        if isinstance(o,list): res += o\n",
    "        else: res.append(o)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our changes with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why donâ€™t scientists trust atoms?  \\nBecause they make up everything!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [\"tell me a joke\"]\n",
    "r, text = openai_chat(mk_msgs(msgs))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'tell me a joke'},\n",
       " ResponseReasoningItem(id='rs_074b10d3bc394aed0069393beb28008196afd1dfe4b20684fc', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseOutputMessage(id='msg_074b10d3bc394aed0069393bec44a88196bb8d3565b6ffa290', content=[ResponseOutputText(annotations=[], text='Why donâ€™t scientists trust atoms?  \\nBecause they make up everything!', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'),\n",
       " {'role': 'user',\n",
       "  'content': \"tell me another joke that's similar to your first joke\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs += [r, \"tell me another joke that's similar to your first joke\"]\n",
    "mm = mk_msgs(msgs)\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the photon refuse to check its luggage?  \\nBecause it was traveling light!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, text = openai_chat(mm)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Azure/OpenAI ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here you go:\\n\\nWhy did the scarecrow win an award?\\n\\nBecause he was outstanding in his field!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [\"tell me a joke\"]\n",
    "r, text = azure_chat(mk_msgs(msgs, api='azure'))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'tell me a joke'},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'Sure! Here you go:\\n\\nWhy did the scarecrow win an award?\\n\\nBecause he was outstanding in his field!'}]},\n",
       " {'role': 'user',\n",
       "  'content': \"tell me another joke that's similar to your first joke\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs += [r, \"tell me another joke that's similar to your first joke\"]\n",
    "mm = mk_msgs(msgs, api='azure')\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely! Hereâ€™s another in the same vein:\\n\\nWhy did the tomato turn red?\\n\\nBecause it saw the salad dressing!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, text = azure_chat(mm)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Anthropic ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [\"tell me a joke\"]\n",
    "r, text = anthropic_chat(mk_msgs(msgs, api='anthropic'))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'tell me a joke'},\n",
       " {'role': 'assistant',\n",
       "  'content': [TextBlock(citations=None, text=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", type='text')]},\n",
       " {'role': 'user',\n",
       "  'content': \"tell me another joke that's similar to your first joke\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs += [r, \"tell me another joke that's similar to your first joke\"]\n",
    "mm = mk_msgs(msgs, api='anthropic')\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't electrons ever pay their bills?\\n\\nBecause they're always negatively charged!\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, text = anthropic_chat(mm)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make `msglm` a little easier to use let's create OpenAI, Azure/OpenAI and Anthropic wrappers for `mk_msg` and `mk_msgs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "mk_msg_openai = partial(mk_msg, api=\"openai\")\n",
    "mk_msgs_openai = partial(mk_msgs, api=\"openai\")\n",
    "mk_msg_azure = partial(mk_msg, api=\"azure\")\n",
    "mk_msgs_azure = partial(mk_msgs, api=\"azure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_msg_anthropic = partial(mk_msg, api=\"anthropic\")\n",
    "mk_msgs_anthropic = partial(mk_msgs, api=\"anthropic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using OpenAI you should be able to use the import below\n",
    "\n",
    "```python\n",
    "from msglm import mk_msg_openai as mk_msg, mk_msgs_openai as mk_msgs\n",
    "```\n",
    "\n",
    "Similarily for Azure/OpenAI\n",
    "\n",
    "```python\n",
    "from msglm import mk_msg_azure as mk_msg, mk_msgs_azure as mk_msgs\n",
    "```\n",
    "\n",
    "Similarily for Anthropic\n",
    "\n",
    "```python\n",
    "from msglm import mk_msg_anthropic as mk_msg, mk_msgs_anthropic as mk_msgs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anthropic currently offers [prompt caching](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching), which can reduce cost and latency.\n",
    "\n",
    "To cache a message, we simply add a `cache_control` field to our content as shown below.\n",
    "\n",
    "```js\n",
    "{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Hello, can you tell me more about the solar system?\",\n",
    "            \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update our `mk_msg` and `mk_msgs` Anthropic wrappers to support caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _add_cache_control(msg, cache=False, ttl=None):\n",
    "    \"cache `msg` with optional ttl.\"\n",
    "    if not cache: return msg\n",
    "    if isinstance(msg[\"content\"], str): msg[\"content\"] = [{\"type\": \"text\", \"text\": msg[\"content\"]}]\n",
    "    cache_control = {\"type\": \"ephemeral\"}\n",
    "    if ttl is not None: cache_control[\"ttl\"] = ttl\n",
    "    if isinstance(msg[\"content\"][-1], dict): msg[\"content\"][-1][\"cache_control\"] = cache_control\n",
    "    elif isinstance(msg[\"content\"][-1], abc.Mapping): msg[\"content\"][-1].cache_control = cache_control\n",
    "    return msg\n",
    "\n",
    "def _remove_cache_ckpts(msg):\n",
    "    \"remove unecessary cache checkpoints.\"\n",
    "    if isinstance(msg[\"content\"], str): msg[\"content\"] = [{\"type\": \"text\", \"text\": msg[\"content\"]}]\n",
    "    elif isinstance(msg[\"content\"][-1], dict): msg[\"content\"][-1].pop('cache_control', None)\n",
    "    else: delattr(msg[\"content\"][-1], 'cache_control') if hasattr(msg[\"content\"][-1], 'cache_control') else None\n",
    "    return msg\n",
    "\n",
    "@delegates(mk_msg)\n",
    "def mk_msg_anthropic(*args, cache=False, ttl=None, **kwargs):\n",
    "    \"Create an Anthropic compatible message.\"\n",
    "    msg = partial(mk_msg, api=\"anthropic\")(*args, **kwargs)\n",
    "    return _add_cache_control(msg, cache=cache, ttl=ttl)\n",
    "\n",
    "@delegates(mk_msgs)\n",
    "def mk_msgs_anthropic(*args, cache=False, ttl=None, cache_last_ckpt_only=False, **kwargs):\n",
    "    \"Create a list of Anthropic compatible messages.\"\n",
    "    msgs = partial(mk_msgs, api=\"anthropic\")(*args, **kwargs)\n",
    "    if cache_last_ckpt_only: msgs = [_remove_cache_ckpts(m) for m in msgs]\n",
    "    if not msgs: return msgs\n",
    "    msgs[-1] = _add_cache_control(msgs[-1], cache=cache, ttl=ttl)\n",
    "    return msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see caching in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_msg_anthropic(\"Don't cache my message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_msg_anthropic(\"Please cache my message\", cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_msg_anthropic(\"Cache for 1 hour\", cache=True, ttl=\"1h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Anthropic API provides detailed [citations](https://docs.anthropic.com/en/docs/build-with-claude/citations) when answering questions about documents.\n",
    "\n",
    "When citations are enabled a citations block like the one below will be included in the response.\n",
    "\n",
    "```js\n",
    "{\n",
    "  \"content\": [\n",
    "    { \"type\": \"text\", \"text\": \"According to the document, \" },\n",
    "    {\n",
    "      \"type\": \"text\", \"text\": \"the grass is green\",\n",
    "      \"citations\": [{\n",
    "        \"type\": \"char_location\",\n",
    "        \"cited_text\": \"The grass is green.\",\n",
    "        \"document_index\": 0, \"document_title\": \"Example Document\",\n",
    "        \"start_char_index\": 0, \"end_char_index\": 20\n",
    "      }]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable citations you need to create an Anthropic document with the following structure.\n",
    "\n",
    "```js\n",
    "{\n",
    "    \"type\": \"document\",\n",
    "    \"source\": {...},\n",
    "    \"title\": \"Document Title\", # optional\n",
    "    \"context\": \"Context about the document that will not be cited from\", # optional\n",
    "    \"citations\": {\"enabled\": True}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently Anthropic supports citations on 3 document types:\n",
    "- text\n",
    "- pdfs\n",
    "- custom\n",
    "\n",
    "A **text** document has the following source structure.\n",
    "\n",
    "```js\n",
    "{\"type\": \"text\", \"media_type\": \"text/plain\", \"data\": \"Plain text content...\"}\n",
    "```\n",
    "\n",
    "Here's the source structure for a **pdf**.\n",
    "\n",
    "```js\n",
    "{\"type\": \"base64\", \"media_type\": \"application/pdf\", \"data\": b64_enc_data}\n",
    "```\n",
    "\n",
    "Finally, here's the source structure for a **custom** document.\n",
    "\n",
    "```js\n",
    "{\n",
    "  \"type\": \"content\",\n",
    "  \"content\": [\n",
    "    {\"type\": \"text\", \"text\": \"First chunk\"},\n",
    "    {\"type\": \"text\", \"text\": \"Second chunk\"}\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_ant_doc(content, title=None, context=None, citation=True, **kws):\n",
    "    \"Create an Anthropic document.\"\n",
    "    if _is_pdf(content): src = {\"type\":\"base64\", \"media_type\":\"application/pdf\", \"data\":_mk_pdf(content)}\n",
    "    elif isinstance(content,list): src = {\"type\":\"content\", \"content\":content}\n",
    "    else: src = {\"type\":\"text\", \"media_type\":\"text/plain\", \"data\":content}\n",
    "    return {\"type\":\"document\", \"source\":src, \"citations\":{\"enabled\":citation}, \"title\":title, \"context\":context, **kws}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you would implement the example from the citation's [docs](https://docs.anthropic.com/en/docs/build-with-claude/citations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = mk_ant_doc(\"The grass is green. The sky is blue.\", title=\"My Document\", context=\"This is a trustworthy document.\")\n",
    "mk_msg([doc, \"What color is the grass and sky?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
